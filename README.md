# Web Mining & NLP - Module 6: Web Scraping and Natural Language Processing on a Webpage

## Summary
In this project, we use Python's requests module to scrape data from a [URL][(https://web.archive.org/web/20210327165005/https://hackaday.com/2021/03/22/how-laser-headlights-work/]).
Next, we utilized modules beautifulsoup4 and html5lib to parse the webpage data and allow us to further conduct analysis.
Then, we leveraged the spaCy module "en_core_web_sm" model along with the collections - counter to conduct NLP on the webpages data.
Finally, we used matplotlib to visualize the findings of frequent tokens and lemmas in the webpage's sentences.

## Skills Used
- VS Code
- GitHub
- Git
- Python
- Jupyter

## Libraries and Modules
- __Requests:__ Used to make HTTP request to gather webpage data.
- __beautifulsoup4:__ Used to parse the returned webpage results.
- __html5lib:__ Also used to parse the returned webpage results.
- __spaCy:__ Used to setup our model and conduct natural language processing.
- __matplotlib:__ Used to customize data vizualization of our returned NLP results.

## Commands Used to Setup and Activate Virtual Environment
- Creating: python -m venv "name-of-your-environment"
- Activating (for Windows): "name-of-your-environment"\Scripts\Activate

## Commands Used to Download Packages
- python -m pip install jupyter
- python -m pip install ipykernel
- python -m pip install beautifulsoup4
- python -m pip install html5lib
- python -m pip install requests
- python -m pip install spacy

## Download and Setup of spaCy
https://spacy.io/usage

## Interested in chatting about this project, data analytics, or just staying in touch?
Connect with me on LinkedIn: [Eric Meyer](https://www.linkedin.com/in/ericmeyer123/)
